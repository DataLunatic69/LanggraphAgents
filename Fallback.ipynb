{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: AgentState, config: RunnableConfig) -> AgentState:\n",
    "    model_type = config[\"configurable\"].get(\"model_type\", \"openai\")\n",
    "    if model_type == \"ollama\":\n",
    "        print(\"Using Ollama (deepseek-r1:7b).\")\n",
    "        llm = ChatOllama(model=\"deepseek-r1\", temperature=0)\n",
    "    else:\n",
    "        print(\"Using (Gemma2-9b-It).\")\n",
    "        llm =ChatGroq(groq_api_key=\"\",model_name=\"llama-3.1-8b-instant\")\n",
    "\n",
    "    messages = [HumanMessage(content=state[\"question\"])]\n",
    "    response = llm.invoke(messages)\n",
    "    state[\"answer\"] = response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Ollama (deepseek-r1:7b).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"What's the highest mountain in the world?\",\n",
       " 'answer': '<think>\\n\\n</think>\\n\\nThe highest mountain in the world is Mount Everest.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_edge(\"agent\", END)\n",
    "graph = workflow.compile()\n",
    "ollama_config = {\n",
    "    \"configurable\": {\n",
    "        \"model_type\": \"ollama\"\n",
    "    }\n",
    "}\n",
    "graph.invoke({\"question\": \"What's the highest mountain in the world?\"}, ollama_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class ModelSwitcher:\n",
    "    def __init__(self, graph: StateGraph):\n",
    "        self.graph = graph\n",
    "        self.last_openai_fail_time = None\n",
    "        self.openai_config = {\n",
    "            \"configurable\": {\n",
    "                \"model_type\": \"gemma\",\n",
    "            }\n",
    "        }\n",
    "        self.fallback_config = {\n",
    "            \"configurable\": {\n",
    "                \"model_type\": \"ollama\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def invoke(self, question: str, remove_think: bool = True) -> str:\n",
    "        if self._should_skip_openai():\n",
    "            return self._invoke_fallback(question, remove_think)\n",
    "\n",
    "        if question.lower() == \"force error\":\n",
    "            print(\"Forcing error with ChatGroq.\")\n",
    "            self.last_openai_fail_time = time.time()\n",
    "            print(\"OpenAI is disabled for 5 minutes. Invoking fallback.\")\n",
    "            return self._invoke_fallback(question, remove_think)\n",
    "\n",
    "        try:\n",
    "            print(\"Attempting invocation with Gemma...\")\n",
    "            state = {\"question\": question, \"answer\": \"\"}\n",
    "            result = self.graph.invoke(state, self.openai_config)\n",
    "            answer = result[\"answer\"]\n",
    "            return self._clean_if_needed(answer, remove_think)\n",
    "        except Exception as e:\n",
    "            print(\"Error with ChatGroq occurred:\", e)\n",
    "            self.last_openai_fail_time = time.time()\n",
    "            print(\"Gemma is disabled for 5 minutes. Invoking fallback.\")\n",
    "            return self._invoke_fallback(question, remove_think)\n",
    "\n",
    "    def _invoke_fallback(self, question: str, remove_think: bool) -> str:\n",
    "        print(\"Using fallback (Ollama).\")\n",
    "        state = {\"question\": question, \"answer\": \"\"}\n",
    "        result = self.graph.invoke(state, self.fallback_config)\n",
    "        answer = result[\"answer\"]\n",
    "        return self._clean_if_needed(answer, remove_think)\n",
    "\n",
    "    def _should_skip_openai(self) -> bool:\n",
    "        if self.last_openai_fail_time is None:\n",
    "            return False\n",
    "        elapsed = time.time() - self.last_openai_fail_time\n",
    "        if elapsed < 300:\n",
    "            remaining = 300 - elapsed\n",
    "            print(f\"Gemma is still in cooldown. Time until Gemma is active again: {remaining:.2f} seconds.\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _clean_if_needed(self, text: str, remove_think: bool) -> str:\n",
    "        if not remove_think:\n",
    "            return text\n",
    "        return self._remove_thinking_tokens(text)\n",
    "\n",
    "    def _remove_thinking_tokens(self, text: str) -> str:\n",
    "        pattern = r\"<think>.*?</think>\"\n",
    "        text_no_think = re.sub(pattern, \"\", text, flags=re.DOTALL)\n",
    "        return text_no_think.lstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting invocation with Gemma...\n",
      "Using (Gemma2-9b-It).\n",
      "Forcing error with ChatGroq.\n",
      "OpenAI is disabled for 5 minutes. Invoking fallback.\n",
      "Using fallback (Ollama).\n",
      "Using Ollama (deepseek-r1:7b).\n",
      "Gemma is still in cooldown. Time until Gemma is active again: 280.02 seconds.\n",
      "Using fallback (Ollama).\n",
      "Using Ollama (deepseek-r1:7b).\n",
      "Gemma is still in cooldown. Time until Gemma is active again: 276.32 seconds.\n",
      "Using fallback (Ollama).\n",
      "Using Ollama (deepseek-r1:7b).\n",
      "Gemma is still in cooldown. Time until Gemma is active again: 273.55 seconds.\n",
      "Using fallback (Ollama).\n",
      "Using Ollama (deepseek-r1:7b).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nThe capital of France is Paris.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_switcher = ModelSwitcher(graph)\n",
    "model_switcher.invoke(\"What's the highest mountain in the world?\")\n",
    "model_switcher.invoke(\"force error\")\n",
    "model_switcher.invoke(\"Which city is the capital of France?\")\n",
    "model_switcher.invoke(\"Which city is the capital of France?\")\n",
    "model_switcher.invoke(\"Which city is the capital of France?\", remove_think=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
